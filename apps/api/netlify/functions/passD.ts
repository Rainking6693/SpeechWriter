import { Handler, HandlerEvent } from '@netlify/functions'\nimport { z } from 'zod'\nimport { drizzle } from 'drizzle-orm/postgres-js'\nimport { eq } from 'drizzle-orm'\nimport postgres from 'postgres'\nimport { speeches, speechSections, modelRuns } from '@speechwriter/database/schema'\nimport jwt from 'jsonwebtoken'\nimport { robustAICall } from './lib/ai-fallback-utils'\nimport { trackSpeechEvent } from './lib/analytics-utils'\nimport { ANALYTICS_EVENTS } from '@speechwriter/analytics'\n\nconst client = postgres(process.env.DATABASE_URL!, { prepare: false })\nconst db = drizzle(client, { schema: { speeches, speechSections, modelRuns } })\n\nconst culturalSensitivitySchema = z.object({\n  speechId: z.string().uuid(),\n  sectionId: z.string().uuid().optional(),\n  text: z.string().min(1),\n  targetAudience: z.string().optional(),\n  culturalContext: z.string().optional()\n})\n\nconst verifyToken = (token: string) => {\n  try {\n    return jwt.verify(token, process.env.NEXTAUTH_SECRET!)\n  } catch {\n    return null\n  }\n}\n\n// Cultural sensitivity lexicon - expandable\nconst SENSITIVITY_PATTERNS = {\n  // Religious references that might be inappropriate\n  religious: [\n    /\\b(crusade|jihad|holy war)\\b/gi,\n    /\\b(infidel|heathen|pagan)\\b/gi,\n    /\\b(chosen people|promised land)\\b/gi\n  ],\n  \n  // Potentially offensive cultural references\n  cultural: [\n    /\\b(primitive|savage|barbaric|uncivilized)\\b/gi,\n    /\\b(third world|developing world)\\b/gi,\n    /\\b(exotic|oriental)\\b/gi\n  ],\n  \n  // Gender and identity sensitivity\n  gender: [\n    /\\b(mankind|manpower|man-made)\\b/gi,\n    /\\b(guys|boys|girls)\\s+(?=when referring to mixed groups)/gi,\n    /\\b(normal|natural)\\s+(?=when referring to heterosexual)/gi\n  ],\n  \n  // Disability and health sensitivity\n  disability: [\n    /\\b(crazy|insane|mental|psycho)\\b/gi,\n    /\\b(lame|dumb|blind to|deaf to)\\b/gi,\n    /\\b(suffers from|victim of|afflicted with)\\b/gi\n  ],\n  \n  // Age-related sensitivity\n  age: [\n    /\\b(old-fashioned|outdated|ancient)\\s+(?=when referring to people)/gi,\n    /\\b(young and naive|inexperienced youth)\\b/gi\n  ],\n  \n  // Economic sensitivity\n  economic: [\n    /\\b(poor|cheap|low-class)\\s+(?=when referring to people)/gi,\n    /\\b(welfare queen|handout|freeloader)\\b/gi\n  ]\n}\n\nconst INCLUSIVE_ALTERNATIVES = {\n  'mankind': 'humanity, humankind, people',\n  'manpower': 'workforce, personnel, staff',\n  'man-made': 'artificial, synthetic, human-made',\n  'guys': 'everyone, folks, team, people',\n  'crazy': 'surprising, remarkable, intense',\n  'insane': 'incredible, amazing, extraordinary',\n  'lame': 'disappointing, weak, ineffective',\n  'blind to': 'unaware of, overlooking',\n  'deaf to': 'ignoring, dismissing',\n  'third world': 'developing nations, emerging economies',\n  'primitive': 'traditional, indigenous, early',\n  'exotic': 'international, diverse, unique'\n}\n\nconst handler: Handler = async (event: HandlerEvent) => {\n  if (event.httpMethod !== 'POST') {\n    return {\n      statusCode: 405,\n      body: JSON.stringify({ error: 'Method not allowed' })\n    }\n  }\n\n  try {\n    // Verify authentication\n    const authHeader = event.headers.authorization\n    if (!authHeader?.startsWith('Bearer ')) {\n      return {\n        statusCode: 401,\n        body: JSON.stringify({ error: 'Unauthorized' })\n      }\n    }\n\n    const token = authHeader.replace('Bearer ', '')\n    const decoded = verifyToken(token) as any\n    if (!decoded?.sub) {\n      return {\n        statusCode: 401,\n        body: JSON.stringify({ error: 'Invalid token' })\n      }\n    }\n\n    const userId = decoded.sub\n\n    // Parse and validate request\n    const body = JSON.parse(event.body || '{}')\n    const { speechId, sectionId, text, targetAudience, culturalContext } = culturalSensitivitySchema.parse(body)\n\n    // Verify speech ownership\n    const [speech] = await db\n      .select()\n      .from(speeches)\n      .where(eq(speeches.id, speechId))\n      .limit(1)\n\n    if (!speech || speech.userId !== userId) {\n      return {\n        statusCode: 404,\n        body: JSON.stringify({ error: 'Speech not found' })\n      }\n    }\n\n    // Track analytics\n    await trackSpeechEvent(userId, speechId, ANALYTICS_EVENTS.CULTURAL_SENSITIVITY_CHECK, {\n      section_id: sectionId,\n      text_length: text.length,\n      has_cultural_context: !!culturalContext\n    })\n\n    // Step 1: Lexicon-based detection\n    const lexiconFlags = detectSensitivityIssues(text)\n\n    // Step 2: AI-powered cultural sensitivity analysis\n    const aiAnalysis = await performAIAnalysis(text, targetAudience, culturalContext, userId, speechId)\n\n    // Step 3: Combine results and generate recommendations\n    const combinedResults = combineAnalysisResults(lexiconFlags, aiAnalysis)\n\n    return {\n      statusCode: 200,\n      headers: {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n      body: JSON.stringify({\n        analysis: combinedResults,\n        recommendations: generateRecommendations(combinedResults),\n        overallRisk: calculateOverallRisk(combinedResults),\n        message: 'Cultural sensitivity analysis completed'\n      })\n    }\n\n  } catch (error) {\n    console.error('Error in cultural sensitivity check:', error)\n    return {\n      statusCode: 500,\n      body: JSON.stringify({ \n        error: 'Failed to perform cultural sensitivity check',\n        details: process.env.NODE_ENV === 'development' ? error.message : undefined\n      })\n    }\n  }\n}\n\n/**\n * Detect sensitivity issues using lexicon patterns\n */\nfunction detectSensitivityIssues(text: string) {\n  const flags = []\n\n  for (const [category, patterns] of Object.entries(SENSITIVITY_PATTERNS)) {\n    for (const pattern of patterns) {\n      const matches = text.match(pattern)\n      if (matches) {\n        for (const match of matches) {\n          flags.push({\n            type: 'lexicon',\n            category,\n            text: match,\n            position: text.indexOf(match),\n            severity: getSeverityLevel(category, match),\n            suggestion: INCLUSIVE_ALTERNATIVES[match.toLowerCase()] || 'Consider more inclusive language'\n          })\n        }\n      }\n    }\n  }\n\n  return flags\n}\n\n/**\n * Perform AI-powered cultural sensitivity analysis\n */\nasync function performAIAnalysis(text: string, targetAudience?: string, culturalContext?: string, userId?: string, speechId?: string) {\n  const prompt = `\nAnalyze the following text for cultural sensitivity issues:\n\n\"${text}\"\n\n${targetAudience ? `Target Audience: ${targetAudience}` : ''}\n${culturalContext ? `Cultural Context: ${culturalContext}` : ''}\n\nPlease identify:\n1. Potentially insensitive language or phrases\n2. Cultural assumptions that might not apply globally\n3. Stereotypes or generalizations\n4. Religious, ethnic, or cultural references that could be problematic\n5. Language that might exclude or marginalize certain groups\n\nFor each issue found, provide:\n- The specific text\n- Why it might be problematic\n- Suggested alternatives\n- Severity level (low, medium, high)\n\nReturn your analysis as a JSON object with this structure:\n{\n  \"issues\": [\n    {\n      \"text\": \"problematic phrase\",\n      \"reason\": \"explanation of why it's problematic\",\n      \"alternatives\": [\"suggestion 1\", \"suggestion 2\"],\n      \"severity\": \"low|medium|high\",\n      \"category\": \"religious|cultural|gender|disability|age|economic|other\"\n    }\n  ],\n  \"overallAssessment\": \"general assessment of the text's cultural sensitivity\",\n  \"recommendations\": [\"general recommendation 1\", \"general recommendation 2\"]\n}\n\nIf no issues are found, return an empty issues array but still provide an overall assessment.`\n\n  try {\n    const response = await robustAICall(\n      [\n        {\n          role: 'system',\n          content: 'You are a cultural sensitivity expert and inclusive language consultant. Analyze text for potential cultural insensitivity while being balanced and practical. Focus on clear issues rather than being overly cautious.'\n        },\n        {\n          role: 'user',\n          content: prompt\n        }\n      ],\n      {\n        model: 'gpt-4',\n        temperature: 0.3, // Lower temperature for more consistent analysis\n        maxTokens: 1500\n      }\n    )\n\n    if (response.success) {\n      try {\n        return JSON.parse(response.content)\n      } catch (parseError) {\n        console.error('Failed to parse AI response:', parseError)\n        return {\n          issues: [],\n          overallAssessment: 'AI analysis completed but response format was invalid',\n          recommendations: ['Please review the text manually for cultural sensitivity']\n        }\n      }\n    } else {\n      return {\n        issues: [],\n        overallAssessment: 'AI analysis unavailable - please review manually',\n        recommendations: ['Consider having the text reviewed by someone from your target audience']\n      }\n    }\n  } catch (error) {\n    console.error('AI analysis failed:', error)\n    return {\n      issues: [],\n      overallAssessment: 'AI analysis failed - manual review recommended',\n      recommendations: ['Please review the text manually for cultural sensitivity']\n    }\n  }\n}\n\n/**\n * Combine lexicon and AI analysis results\n */\nfunction combineAnalysisResults(lexiconFlags: any[], aiAnalysis: any) {\n  const allIssues = [\n    ...lexiconFlags,\n    ...(aiAnalysis.issues || []).map((issue: any) => ({\n      ...issue,\n      type: 'ai'\n    }))\n  ]\n\n  // Remove duplicates based on similar text\n  const uniqueIssues = allIssues.filter((issue, index, array) => {\n    return !array.slice(0, index).some(prevIssue => \n      prevIssue.text.toLowerCase().includes(issue.text.toLowerCase()) ||\n      issue.text.toLowerCase().includes(prevIssue.text.toLowerCase())\n    )\n  })\n\n  return {\n    issues: uniqueIssues,\n    overallAssessment: aiAnalysis.overallAssessment || 'Analysis completed',\n    aiRecommendations: aiAnalysis.recommendations || []\n  }\n}\n\n/**\n * Generate actionable recommendations\n */\nfunction generateRecommendations(analysis: any) {\n  const recommendations = [...(analysis.aiRecommendations || [])]\n\n  if (analysis.issues.length === 0) {\n    recommendations.push('No significant cultural sensitivity issues detected')\n    recommendations.push('Consider having the text reviewed by members of your target audience')\n  } else {\n    const highSeverityIssues = analysis.issues.filter((issue: any) => issue.severity === 'high')\n    const mediumSeverityIssues = analysis.issues.filter((issue: any) => issue.severity === 'medium')\n\n    if (highSeverityIssues.length > 0) {\n      recommendations.push(`Address ${highSeverityIssues.length} high-priority sensitivity issue(s) before proceeding`)\n    }\n\n    if (mediumSeverityIssues.length > 0) {\n      recommendations.push(`Review ${mediumSeverityIssues.length} medium-priority sensitivity issue(s)`)\n    }\n\n    recommendations.push('Consider having the revised text reviewed by cultural consultants')\n    recommendations.push('Test key phrases with members of your target audience')\n  }\n\n  return recommendations\n}\n\n/**\n * Calculate overall risk level\n */\nfunction calculateOverallRisk(analysis: any): 'low' | 'medium' | 'high' {\n  const issues = analysis.issues || []\n  \n  const highSeverityCount = issues.filter((issue: any) => issue.severity === 'high').length\n  const mediumSeverityCount = issues.filter((issue: any) => issue.severity === 'medium').length\n  \n  if (highSeverityCount > 0) {\n    return 'high'\n  } else if (mediumSeverityCount > 2) {\n    return 'high'\n  } else if (mediumSeverityCount > 0 || issues.length > 3) {\n    return 'medium'\n  } else {\n    return 'low'\n  }\n}\n\n/**\n * Get severity level for lexicon matches\n */\nfunction getSeverityLevel(category: string, match: string): 'low' | 'medium' | 'high' {\n  const highSeverityTerms = ['savage', 'barbaric', 'primitive', 'infidel', 'heathen']\n  const mediumSeverityTerms = ['crazy', 'insane', 'lame', 'blind to', 'deaf to']\n  \n  if (highSeverityTerms.some(term => match.toLowerCase().includes(term))) {\n    return 'high'\n  } else if (mediumSeverityTerms.some(term => match.toLowerCase().includes(term))) {\n    return 'medium'\n  } else {\n    return 'low'\n  }\n}\n\nexport { handler }"